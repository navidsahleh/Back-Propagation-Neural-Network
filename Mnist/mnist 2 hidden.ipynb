{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation Neural Network on Mnist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### report no.1 Reza Sahle, Alireza Rajabi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation efficiently computes the gradient of the loss function with respect to the weights of the network for a single input-output example. This makes it feasible to use gradient methods for training multi-layer networks, updating weights to minimize loss; commonly one uses gradient descent or variants such as stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we have 4200 samples that has labeled on 10 featuers,we used multi layer perceptrone and Back propagation learning role which help us to update our weights in each epochs to find the better acuuracy. to many epochs tends to overfitting, that in statistical we said low bias and high variance so we cant find a good model for test dataset, and low number of epochs mybe cant fit the model on our data and in other word it cause low variance and high bias, so we tried different number of epechs to find the best trade-off on bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so what we done is sperate 1000 of them to train our Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also we have other optimizing parameters such as learning rate (in our code shown as q) and momentum (shown as momen) and most of importance we have diffrent kinds of activation functions. ( here we uesd RelU, sigmoid and tanh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first of all we import some librarys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label= pd.get_dummies(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,label],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['label'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 794 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  0  1  2  3  4  5  6  7  8  9  \n",
       "0       0  ...  0  1  0  0  0  0  0  0  0  0  \n",
       "1       0  ...  1  0  0  0  0  0  0  0  0  0  \n",
       "2       0  ...  0  1  0  0  0  0  0  0  0  0  \n",
       "3       0  ...  0  0  0  0  1  0  0  0  0  0  \n",
       "4       0  ...  1  0  0  0  0  0  0  0  0  0  \n",
       "\n",
       "[5 rows x 794 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we convert our dataframe into a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now we introduced our activation functions and their derivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function (sigmoid)\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivation of activation function(sigmoid)\n",
    "def der_sigmoid(x):\n",
    "    return x * (1.0-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function\n",
    "def tanh(x):\n",
    "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return np.maximum(0,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_relu(X):\n",
    "    return np.where(X <= 0,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we set 1000 samples for our training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input layer\n",
    "X_train = data[:1000,:784]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input layer\n",
    "y_train = data[:1000,784:]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and 500 samples for our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input layer\n",
    "X_test = data[1000:1500,:784]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input layer\n",
    "y_test = data[1000:1500,784:]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### here we initilized our weights. the weights that we generate are in interval of [-1,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and also we peresents number of neurons here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights for first and second layer\n",
    "w1_1 = np.random.uniform(-1,1,(784,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb1=np.random.uniform(0,1,(1,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights for second and third layer3\n",
    "w2_2 = np.random.uniform(-1,1,(90,70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb2=np.random.uniform(0,1,(1,70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights for third and fourth layer\n",
    "w3_3 = np.random.uniform(-1,1,(70,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb3=np.random.uniform(0,1,(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the momentum parameter will regularize the velocity of updating weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel1=np.zeros_like(w1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel2=np.zeros_like(w2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel3=np.zeros_like(w3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bias in every layer in theory should make the accuracy better, but here we reach the 93% accuracy without bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=np.zeros((1000,1))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2=np.zeros((1000,1))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3=np.zeros((1000,1))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goal of this below 3 lines: since we make random weights, we cant say that our changes on parameter changes helping us, so we hold the values every time to make the results only related to our tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=np.copy(w1_1)\n",
    "w2=np.copy(w2_2)\n",
    "w3=np.copy(w3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first we calculate the forward propagation then we copmutes the cost functions (witch is the mean squared error) and finally we calculate the back propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction:\n",
      " [[1.11845797e-03 9.09038152e-01 2.89547528e-01 9.95082953e-03\n",
      "  8.23802797e-03 1.48123079e-02 7.05469913e-03 6.15255053e-03\n",
      "  4.17135576e-02 3.95320015e-03]\n",
      " [9.74068821e-01 1.67792413e-03 8.23751329e-02 1.37828602e-02\n",
      "  2.95059670e-03 2.10395710e-02 3.74419626e-02 6.67636513e-03\n",
      "  5.37931253e-03 5.52380970e-04]\n",
      " [1.11204416e-02 9.38820668e-01 1.89211242e-02 5.38120620e-03\n",
      "  1.49060949e-03 2.51895494e-02 1.28044506e-02 6.86571862e-02\n",
      "  1.22278243e-02 1.71629963e-02]\n",
      " [1.72013871e-02 3.71015866e-03 2.19062137e-01 1.90663698e-03\n",
      "  4.55995064e-02 1.54951108e-02 9.94330795e-02 3.78409074e-03\n",
      "  2.54683963e-02 8.94607013e-03]]\n",
      "\n",
      " the output:\n",
      " [[0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]]\n",
      "the cost:\n",
      " 154.2666795473991\n"
     ]
    }
   ],
   "source": [
    "lis = []\n",
    "for i in range(3000):\n",
    "\n",
    "    #forward propagation\n",
    "    \n",
    "    #second layer output with 3 neuron\n",
    "    z2=np.dot(X_train,w1)+np.dot(b1,wb1)\n",
    "    a2=sigmoid(z2)\n",
    "    \n",
    "    #third layer output with 2 neuron\n",
    "\n",
    "    z3=np.dot(a2,w2)+np.dot(b2,wb2)\n",
    "    a3=sigmoid(z3)\n",
    "\n",
    "    \n",
    "    #fourth layer(final layer) with 1 neuron\n",
    "\n",
    "    z4=np.dot(a3,w3)+np.dot(b3,wb3)\n",
    "    a4=sigmoid(z4)\n",
    "    \n",
    "    \n",
    "    #Backpropagation\n",
    "    \n",
    "    #cost = (abs(y_train - a4)).mean()\n",
    "    cost = 0.5 * (y_train - a4)**2\n",
    "    lis.append(np.sum(cost))\n",
    "    \n",
    "    #print('train',i,':',np.sum(cost))\n",
    "    #derviation of cost function for w3\n",
    "    delta4= (y_train - a4) * (der_sigmoid(a4))\n",
    "    gamma3=np.dot(a3.T,delta4)\n",
    "    \n",
    "    \n",
    "    delta3 = np.dot(delta4,w3.T) * (der_sigmoid(a3))\n",
    "    gamma2 = np.dot(a2.T,delta3)\n",
    "    \n",
    "    delta2 = np.dot(delta3,w2.T) * (der_sigmoid(a2))\n",
    "    gamma1 = np.dot(X_train.T, delta2) \n",
    "    \n",
    "    #updating the weights\n",
    "\n",
    "    #learning rate\n",
    "    q=0.3\n",
    "    momen=0.1\n",
    "    \n",
    "    vel1=momen*vel1+q*(gamma1)\n",
    "    vel2=momen*vel2+q*(gamma2)\n",
    "    vel3=momen*vel3+q*(gamma3)\n",
    "    \n",
    "   # w3 += (q*(1/1000)*gamma3)\n",
    "    w1= w1+(1/1000)*vel1\n",
    "   # w2 += (q*(1/1000)*gamma2)\n",
    "    w2= w2+(1/1000)*vel2\n",
    "   # w1 += (q*(1/1000)*gamma1)\n",
    "    w3= w3+(1/1000)*vel3\n",
    "\n",
    "\n",
    "print('the prediction:\\n',a4[:4])\n",
    "print('\\n the output:\\n',y_train[:4])\n",
    "print('the cost:\\n',np.sum(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward propagation\n",
    "    \n",
    "#second layer output with 3 neuron\n",
    "z2=np.dot(X_test,w1)\n",
    "\n",
    "#use this only for tanh problem:\n",
    "#(z2=(z2 - z2.min())/(z2.max() - z2.min()))\n",
    "\n",
    "a2=sigmoid(z2)\n",
    "    \n",
    "#third layer output with 2 neuron\n",
    "\n",
    "z3=np.dot(a2,w2)\n",
    "a3=sigmoid(z3)\n",
    "\n",
    "    \n",
    "#fourth layer(final layer) with 1 neuron\n",
    "\n",
    "z4=np.dot(a3,w3)\n",
    "a4=sigmoid(z4)\n",
    "    \n",
    "    \n",
    "#Backpropagation\n",
    "    \n",
    "#cost = (abs(y_train - a4)).mean()\n",
    "cost = 0.5 * (y_test - a4)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### since our outputs has a probable values we set them to unitary vectors such as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.zeros((a4.shape[0],a4.shape[1]))\n",
    "for i in range(a4.shape[0]):\n",
    "    for j in range(a4.shape[1]):\n",
    "        if LA.norm(a4[i],np.inf)==a4[i,j]:\n",
    "            arr[i,j]=1\n",
    "        else:\n",
    "            arr[i,j]=0\n",
    "            \n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to calculate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84        43\n",
      "           1       0.78      0.95      0.86        61\n",
      "           2       0.62      0.85      0.72        62\n",
      "           3       0.00      0.00      0.00        35\n",
      "           4       0.00      0.00      0.00        49\n",
      "           5       0.53      0.57      0.55        49\n",
      "           6       0.80      0.78      0.79        55\n",
      "           7       0.60      0.78      0.68        49\n",
      "           8       0.51      0.62      0.56        48\n",
      "           9       0.51      0.69      0.59        49\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       500\n",
      "   macro avg       0.52      0.61      0.56       500\n",
      "weighted avg       0.54      0.64      0.58       500\n",
      " samples avg       0.64      0.64      0.64       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,arr))\n",
    "print(classification_report(y_test,arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean squared error for train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x75512e8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(10,6))\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.plot(range(0,3000),lis,label='MSE in train')\n",
    "ax.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
